primary_name: "Shuzheng Si"
secondary_name: ""
navbar_name: "Shuzheng Si's Homepage üëãüèª"

positions:
  - '<span class="no-break"><img src="assets/images/badges/tsinghua.png" alt="Tsinghua University" class="inline-badge"/></span> Ph.D. student, Tsinghua University'

email: "ssz24@mails.tsinghua.edu.cn"
gscholar: zO2XyZUAAAAJ
github: S1s-Z
# twitter: RongshengWang
# wechat_qrcode: assets/images/etc/wechat.jpg
# wechat_prompt: >-
#   Please tell me your <strong>name</strong> and <strong>affiliation</strong> (current or past) when adding my wechat. Thanks!
# zhihu: wang-rong-sheng-74
# resume: assets/cv/Resume_RongshengWang.pdf
# linkedin: your-linked-in-id
# orcid: 0000-0000-0000-0000
# xiaohongshu: 5fa2663000000000010068e2

short_bio: >-
  Hi, I‚Äôm Shuzheng Si, a second-year CS Ph.D. student at Tsinghua University. I am lucky to be advised by Prof. <a href="https://scholar.google.com/citations?hl=en&user=zIgT0HMAAAAJ">Maosong Sun</a> and affiliated with <a href="https://nlp.csai.tsinghua.edu.cn">TsinghuaNLP Lab</a>. Previously, I obtained my master‚Äôs degree from Peking University, where I was fortunate to be a part of the <a href="https://pkunlp-icler.github.io/">PKU NLP Group</a> under the supervision of Prof. <a href="https://scholar.google.com.au/citations?user=LaKNyhQAAAAJ">Baobao Chang</a>. My research interests lie in <b>Natural Language Processing (NLP) and Large Language Models (LLMs)</b>, specifically focusing on <b>Data-Centric NLP</b>, including:
  <br>
  <ul class="pub">
      <li>
          üìñ <b>Theoretical Perspective ‚Äî Understanding Data Scientifically</b>: My first line of research aims to obtain data more scientifically (<a href="https://arxiv.org/abs/2505.16483">CANOE</a>, <a href="https://arxiv.org/abs/2309.07915">MMICL</a>, <a href="https://arxiv.org/abs/2502.04153">UltraIF</a>, <a href="https://arxiv.org/abs/2407.05282">UltraEdit</a>), as well as ensure the data quality automatically (<a href="https://arxiv.org/abs/2502.07340">NOVA</a>, <a href="https://arxiv.org/abs/2410.15633">GATEAU</a>, <a href="https://arxiv.org/abs/2312.10302">NUGGETS</a>). In this way, we can gain a deeper understanding of the role of data in LLM training. For instance, when enhancing the specific capabilities of LLMs, such as long-context understanding, what characteristics should the selected data possess to be considered high-quality data?
      </li>
      <li>
          üöÄ <b>Methodological Perspective ‚Äî Leveraging Data Efficiently</b>: This line of research attempts to utilize the supervision derived from training data more efficiently and effectively, such as leveraging noisy data from real-world scenarios to train models (<a href="https://arxiv.org/abs/2305.13040">SpokenWOZ</a>, <a href="https://arxiv.org/abs/2305.04076">SANTA</a>, <a href="https://arxiv.org/abs/2311.08010">CENSOR</a>, <a href="https://arxiv.org/abs/2209.01646">SCL-RAI</a>), and training models in low-resource/low-compute settings (<a href="https://arxiv.org/abs/2510.05608">EAGLET</a>, <a href="https://arxiv.org/abs/2404.08491">ALSACE</a>, <a href="https://arxiv.org/abs/2411.14279">LACING</a>). 
      </li>
      <li>
          üåè <b>Applied Perspective ‚Äî Building Information-Seeking Tools</b>: I also spend some time applying my research to build LLM-based information-seeking applications, e.g., <a href="https://lingowhale.com/">LingoWhale</a> and <a href="https://zhiliao.news/">Zhiliao News</a>, which were released by DeepLang AI and TsinghuaNLP Lab. To date, these applications have provided intelligent text information processing services to hundreds of thousands of Chinese users.
      </li>
  </ul>

  My research goal is to elucidate the influence of data on LLMs and utilize these insights to guide the construction of data, thereby building the LLM-based language processing engine. Recently, I have been interested in investigating LLMs' hallucinations from a data perspective and exploring data-driven hallucination mitigation methods for information-seeking tools. üïäüïäüïä





show_portrait: True
portrait_url: assets/images/photos/ssz3.jpg
portrait_caption: >-
  Welcome to my homepage! This photo was taken before I started my research in NLP. Compared to back then, I've gained quite a bit of weight and lost quite a bit of hair :(

education:
- name: Tsinghua University
  logo: assets/images/badges/tsinghua.png
  position: Ph.D. in Computer Science and Technology
  date: Sep. 2024 - Jul. 2028 (expected)
- name: Peking University 
  logo: assets/images/badges/PKU_red.png
  position: M.S. in Software Engineering
  date: Sep. 2021 - Jul. 2024
- name: Yunnan University 
  logo: assets/images/badges/ynu.png
  position: "B.S. in Information Security (Rank: 1/300+)"
  date: Sep. 2017 - Jul. 2021
  

experience:
- name: DeepLang AI
  logo: assets/images/badges/deeplang.png
  position: Research Intern
  date: Apr. 2024 - Now
- name: Alibaba DAMO Academy
  logo: assets/images/badges/ali.png
  position: Research Intern
  date: Jun. 2022 - Jun. 2023
- name: SenseTime Research
  logo: assets/images/badges/sensetime.png
  position: Research Intern
  date: Jul. 2021 -	Feb. 2022


awards:
- name: Merit Student (Top 5% in PKU)
  date: 2022
- name: "Top 10 Outstanding Students Nomination Award (Ranked 1st)"
  date: 2020
- name: First-Class Scholarship
  date: 2020
- name: National Scholarship
  date: 2019
- name: Provincial Scholarship
  date: 2018
- name: Provincial Merit Student
  date: 2018
  
service:
- name: "NLP Research Communities: Reviewer of ACL, EMNLP, NAACL, COLING, and TASLP"
- name: "ML Research Communities: Reviewer of NeurIPS, ICLR, and ICML"
- name: "CV Research Communities: Reviewer of ICCV"
- name: I am also a member of the <a href="https://huggingface.co/birdsql">BIRD team</a>, led by the talent researcher Jinyang Li, which drives the development of text-to-SQL for real-world database applications

